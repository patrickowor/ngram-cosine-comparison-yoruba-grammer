{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7168214,"sourceType":"datasetVersion","datasetId":4141226}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ngram model with cosine similarities","metadata":{}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-12-12T16:03:23.818495Z","iopub.execute_input":"2023-12-12T16:03:23.819233Z","iopub.status.idle":"2023-12-12T16:03:39.343324Z","shell.execute_reply.started":"2023-12-12T16:03:23.819161Z","shell.execute_reply":"2023-12-12T16:03:39.341682Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.11.17)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm /kaggle/working/yoruba.csv","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:14:47.236387Z","iopub.execute_input":"2023-12-12T11:14:47.236946Z","iopub.status.idle":"2023-12-12T11:14:48.379944Z","shell.execute_reply.started":"2023-12-12T11:14:47.236908Z","shell.execute_reply":"2023-12-12T11:14:48.377414Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import gdown\n\n\nurl = 'https://drive.google.com/uc?id=1WgQ6v9fuEdMn8My6ELXfeVaSJ7asAaUJ'\n\noutput = 'yoruba.txt'\n\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:14:49.542834Z","iopub.execute_input":"2023-12-12T11:14:49.544059Z","iopub.status.idle":"2023-12-12T11:14:52.857251Z","shell.execute_reply.started":"2023-12-12T11:14:49.544002Z","shell.execute_reply":"2023-12-12T11:14:52.856018Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1WgQ6v9fuEdMn8My6ELXfeVaSJ7asAaUJ\nTo: /kaggle/working/yoruba.txt\n100%|██████████| 70.2M/70.2M [00:00<00:00, 236MB/s]\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'yoruba.txt'"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('embedings-ngram-3.pt')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:17:25.256809Z","iopub.execute_input":"2023-12-12T13:17:25.257195Z","iopub.status.idle":"2023-12-12T13:17:25.263752Z","shell.execute_reply.started":"2023-12-12T13:17:25.257166Z","shell.execute_reply":"2023-12-12T13:17:25.262836Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/embedings-ngram-3.pt","text/html":"<a href='embedings-ngram-3.pt' target='_blank'>embedings-ngram-3.pt</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"FileLink('tokenized.txt')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:17:22.792328Z","iopub.execute_input":"2023-12-12T13:17:22.793288Z","iopub.status.idle":"2023-12-12T13:17:22.799468Z","shell.execute_reply.started":"2023-12-12T13:17:22.793234Z","shell.execute_reply":"2023-12-12T13:17:22.798434Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/tokenized.txt","text/html":"<a href='tokenized.txt' target='_blank'>tokenized.txt</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:27.510114Z","iopub.execute_input":"2023-12-12T12:08:27.510487Z","iopub.status.idle":"2023-12-12T12:08:28.369701Z","shell.execute_reply.started":"2023-12-12T12:08:27.510455Z","shell.execute_reply":"2023-12-12T12:08:28.368922Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:28.371250Z","iopub.execute_input":"2023-12-12T12:08:28.371642Z","iopub.status.idle":"2023-12-12T12:08:41.172663Z","shell.execute_reply.started":"2023-12-12T12:08:28.371605Z","shell.execute_reply":"2023-12-12T12:08:41.171474Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.35.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer('bert-base-multilingual-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:41.174762Z","iopub.execute_input":"2023-12-12T12:08:41.175075Z","iopub.status.idle":"2023-12-12T12:08:55.054035Z","shell.execute_reply.started":"2023-12-12T12:08:41.175046Z","shell.execute_reply":"2023-12-12T12:08:55.053182Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_ngrams(text, n):\n    word_doc = []\n    doc_list = text.split()\n    if len(doc_list) <= n:\n        word_doc.append(' '.join(doc_list))\n    else :\n        for i in range(n, len(doc_list) +1):\n            word_doc.append(' '.join(doc_list[i-n : i]))\n    return word_doc","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.055178Z","iopub.execute_input":"2023-12-12T12:08:55.055657Z","iopub.status.idle":"2023-12-12T12:08:55.061546Z","shell.execute_reply.started":"2023-12-12T12:08:55.055628Z","shell.execute_reply":"2023-12-12T12:08:55.060528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()\n    text = text.replace('\\n', '').replace('\\t', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')\n    text = text.translate(str.maketrans('','', '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'))\n    doc = text.split()\n    text = ' '.join(doc)\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.064108Z","iopub.execute_input":"2023-12-12T12:08:55.064805Z","iopub.status.idle":"2023-12-12T12:08:55.074248Z","shell.execute_reply.started":"2023-12-12T12:08:55.064735Z","shell.execute_reply":"2023-12-12T12:08:55.073347Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def read_dataset(*links):\n    dataset = []\n    for link in links:\n        with open(link, 'r', encoding='utf-8') as file:\n            #  text = file.read()\n            for tt in file:\n                text = tt\n                text = preprocess_text(text)\n                if text.strip() != '':\n                    dataset.append(text)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.075370Z","iopub.execute_input":"2023-12-12T12:08:55.075667Z","iopub.status.idle":"2023-12-12T12:08:55.087611Z","shell.execute_reply.started":"2023-12-12T12:08:55.075616Z","shell.execute_reply":"2023-12-12T12:08:55.086735Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def gather_ngrams(ds, n):\n    ngrams = []\n    for text in ds:\n        n_list = build_ngrams(text, n)\n        ngrams.extend(n_list)\n    return ngrams","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.089009Z","iopub.execute_input":"2023-12-12T12:08:55.089273Z","iopub.status.idle":"2023-12-12T12:08:55.099074Z","shell.execute_reply.started":"2023-12-12T12:08:55.089250Z","shell.execute_reply":"2023-12-12T12:08:55.098212Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def create_embedder(phrases):\n    emb = model.encode(phrases)\n    emb = torch.tensor(emb) \n    emb /= emb.norm(dim=-1, p=2).unsqueeze(-1) \n    return emb","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.099983Z","iopub.execute_input":"2023-12-12T12:08:55.100218Z","iopub.status.idle":"2023-12-12T12:08:55.110638Z","shell.execute_reply.started":"2023-12-12T12:08:55.100198Z","shell.execute_reply":"2023-12-12T12:08:55.109798Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def generate_ngram_model(ngrams, ngram_n):\n    embedings = create_embedder(ngrams)\n    torch.save(embedings, f'embedings-ngram-{ngram_n}.pt')\n    with open('tokenized.txt', 'w') as ngram_file:\n        ngram_file.write(str(ngrams))\n    print(f'created embedings-ngram-{ngram_n}.pt and tokenized.txt')\n    \n# generate_ngram_model(ngrams, 3)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:12:42.076029Z","iopub.execute_input":"2023-12-12T13:12:42.077005Z","iopub.status.idle":"2023-12-12T13:12:42.082436Z","shell.execute_reply.started":"2023-12-12T13:12:42.076970Z","shell.execute_reply":"2023-12-12T13:12:42.081513Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def predict(text, ngram_n, ngrams):\n    phrase = create_embedder([text])\n    print('loading_embbedings')\n    embedings =torch.load(f'/kaggle/working/embedings-ngram-{ngram_n}.pt')\n    print('loading_complete')\n    sims = embedings @ phrase.t()\n    return sims[:,0]","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.126711Z","iopub.execute_input":"2023-12-12T12:08:55.126986Z","iopub.status.idle":"2023-12-12T12:08:55.134678Z","shell.execute_reply.started":"2023-12-12T12:08:55.126963Z","shell.execute_reply":"2023-12-12T12:08:55.133949Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def final_result(text, ngram_n):\n    ds = read_dataset('/kaggle/input/ngram-yoruba/bibeli_Mimo.txt')\n    ngrams = gather_ngrams(ds, ngram_n)\n    ngrams = list(set(ngrams))\n    sims = predict(text, ngram_n, ngrams)\n    greatest = max(sims)\n    index_max = np.argmax(sims)\n    return {\"text\": ngrams[int(index_max)], \"index\" : index_max,'similarity': greatest}","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.135660Z","iopub.execute_input":"2023-12-12T12:08:55.135924Z","iopub.status.idle":"2023-12-12T12:08:55.146395Z","shell.execute_reply.started":"2023-12-12T12:08:55.135901Z","shell.execute_reply":"2023-12-12T12:08:55.145572Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def final_n_result(text, ngram_n, no_of_results):\n    if no_of_results < 1:\n        raise Exception(\"Sorry, no numbers below one\")\n    ds = read_dataset('/kaggle/input/ngram-yoruba/bibeli_Mimo.txt')\n    ngrams = gather_ngrams(ds, ngram_n)\n    ngrams = list(set(ngrams))\n    sims = predict(text, ngram_n, ngrams)\n    ind = np.argpartition(sims, -1 * no_of_results )[ -1 * no_of_results:]\n    resp = []\n    for i in ind:\n        similarity = sims[i]\n        index_max = i\n        resp.append({\"text\": ngrams[int(index_max)], \"index\" : index_max,'similarity': similarity})\n    return resp","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:55.147406Z","iopub.execute_input":"2023-12-12T12:08:55.147697Z","iopub.status.idle":"2023-12-12T12:08:55.157310Z","shell.execute_reply.started":"2023-12-12T12:08:55.147673Z","shell.execute_reply":"2023-12-12T12:08:55.156504Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def final_ngram_result(text,ngrams, ngram_n, no_of_results):\n    if no_of_results < 1:\n        raise Exception(\"Sorry, no numbers below one\")\n    if no_of_results > len(ngrams):\n        no_of_results = len(ngrams)\n    print(no_of_results,len(ngrams) )\n    sims = predict(text, ngram_n, ngrams)\n    ind = np.argpartition(sims, -1 * no_of_results )[ -1 * no_of_results:]\n    resp = []\n    check = []\n    final_obj = {}\n    obj_score = {}\n    for i in ind:\n        similarity = sims[i]\n        index_max = i\n        if similarity >= 1:\n            return []\n#         if ngrams[int(index_max)] not in check:\n#             check.append(ngrams[int(index_max)])\n#             if obj_score.get(similarity) == None:\n#                 obj_score[similarity] = ngrams[int(index_max)]\n#                 final_obj[ngrams[int(index_max)]] = []\n#             final_obj[obj_score[similarity]].append({\"text\": ngrams[int(index_max)], \"index\" : index_max,'similarity': similarity})\n        resp.append({\"text\": ngrams[int(index_max)], \"index\" : index_max,'similarity': similarity})\n        \n    return resp #list(reversed(sorted(resp, key=lambda d: d['similarity']) ))","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:38:12.582729Z","iopub.execute_input":"2023-12-12T13:38:12.583514Z","iopub.status.idle":"2023-12-12T13:38:12.591424Z","shell.execute_reply.started":"2023-12-12T13:38:12.583470Z","shell.execute_reply":"2023-12-12T13:38:12.590399Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def read_tokenizer(link):\n    with open(link, \"r\") as f:\n        return eval(f.read())","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:38:12.807251Z","iopub.execute_input":"2023-12-12T13:38:12.807642Z","iopub.status.idle":"2023-12-12T13:38:12.815457Z","shell.execute_reply.started":"2023-12-12T13:38:12.807599Z","shell.execute_reply":"2023-12-12T13:38:12.814499Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"['fúngbà díẹ̀ níbi',\n 'fún àjọ yìí',\n 'àwọ̀lékè rẹ̀ ya',\n 'ogún èèyàn péré',\n '4200 dọ́là ilẹ̀',\n 'sọ nípa ikú',\n 'ń ṣáájú nínú',\n 'ṣètò ibi táwọn',\n 'sì tọ́ ọ',\n 'ará samáríà séèyàn']"},"metadata":{}}]},{"cell_type":"code","source":"text = 'fúngbà díẹ̀ níb'#input('enter yoruba text:')\nngrams_value = 3\n\n# generate_ngram_model(ngrams, ngrams_value)\n# final_result(text, ngrams_value)\nngrams = read_tokenizer('/kaggle/working/tokenized.txt')\nfinal_ngram_result(text,ngrams, ngrams_value, 25)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:38:32.094616Z","iopub.execute_input":"2023-12-12T13:38:32.095001Z","iopub.status.idle":"2023-12-12T13:38:32.146670Z","shell.execute_reply.started":"2023-12-12T13:38:32.094974Z","shell.execute_reply":"2023-12-12T13:38:32.145764Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"10 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db02e89c67044ca690a864f16f222fa9"}},"metadata":{}},{"name":"stdout","text":"loading_embbedings\nloading_complete\n","output_type":"stream"},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"[{'text': 'àwọ̀lékè rẹ̀ ya', 'index': tensor(2), 'similarity': tensor(0.4664)},\n {'text': 'fún àjọ yìí', 'index': tensor(1), 'similarity': tensor(0.5944)},\n {'text': 'fúngbà díẹ̀ níbi',\n  'index': tensor(0),\n  'similarity': tensor(0.9480)},\n {'text': 'ogún èèyàn péré', 'index': tensor(3), 'similarity': tensor(0.5864)},\n {'text': '4200 dọ́là ilẹ̀', 'index': tensor(4), 'similarity': tensor(0.5185)},\n {'text': 'sọ nípa ikú', 'index': tensor(5), 'similarity': tensor(0.6276)},\n {'text': 'ń ṣáájú nínú', 'index': tensor(6), 'similarity': tensor(0.6945)},\n {'text': 'ṣètò ibi táwọn', 'index': tensor(7), 'similarity': tensor(0.4875)},\n {'text': 'sì tọ́ ọ', 'index': tensor(8), 'similarity': tensor(0.6512)},\n {'text': 'ará samáríà séèyàn',\n  'index': tensor(9),\n  'similarity': tensor(0.6629)}]"},"metadata":{}}]},{"cell_type":"code","source":"# ds = read_dataset('/kaggle/working/yoruba.txt')\n# ngrams_value = 3\n# ngrams = gather_ngrams(ds, ngrams_value)\n# print(len(ngrams))\n# ngrams = list(set(ngrams))\n# print(len(ngrams))\n# print(ngrams[:5])\n# generate_ngram_model(ngrams, ngrams_value)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T12:08:58.644551Z","iopub.execute_input":"2023-12-12T12:08:58.645204Z","iopub.status.idle":"2023-12-12T12:09:16.982029Z","shell.execute_reply.started":"2023-12-12T12:08:58.645168Z","shell.execute_reply":"2023-12-12T12:09:16.981047Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"9216779\n2778269\n['fúngbà díẹ̀ níbi', 'fún àjọ yìí', 'àwọ̀lékè rẹ̀ ya', 'ogún èèyàn péré', '4200 dọ́là ilẹ̀']\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_ngram_model(ngrams, ngrams_value)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T13:32:59.505247Z","iopub.execute_input":"2023-12-12T13:32:59.506273Z","iopub.status.idle":"2023-12-12T13:32:59.550292Z","shell.execute_reply.started":"2023-12-12T13:32:59.506228Z","shell.execute_reply":"2023-12-12T13:32:59.549395Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1440d9491fe74cd38dc5de865d8a550a"}},"metadata":{}},{"name":"stdout","text":"created embedings-ngram-3.pt and tokenized.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"# ! rm /kaggle/working/embedings-ngram-3.pt\n! rm /kaggle/working/tokenized.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}